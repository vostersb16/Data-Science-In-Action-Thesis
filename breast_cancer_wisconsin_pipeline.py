# -*- coding: utf-8 -*-
"""Breast_Cancer_Wisconsin_Pipeline.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/122Qo7XEwwJ9TCZHityQoZyXE7YyNL-dD

# **1) Import all packages**
"""

import os
import numpy as np 
import pandas as pd
import tensorflow as tf
import matplotlib.pyplot as plt
import keras
import math
from tensorflow.python.client import device_lib
from sklearn.model_selection import train_test_split 
from numpy.random import seed
from keras.callbacks import ModelCheckpoint
from keras.callbacks import EarlyStopping
seed(42)
import tensorflow as tf
tf.random.set_seed(42)
from sklearn.metrics import roc_auc_score
from sklearn import tree
from sklearn.tree import DecisionTreeClassifier,DecisionTreeRegressor
from sklearn.linear_model import LogisticRegression
from sklearn import metrics 
from scipy.special import logit
from keras import backend as K
from sklearn.preprocessing import MinMaxScaler, Normalizer
from keras.models import Sequential
from keras.utils import to_categorical
from keras.regularizers import l1,l2
from tensorflow.keras import layers, models
from tensorflow.keras.models import Model
from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix, roc_auc_score, roc_curve

"""# **2) Prepare Data**"""

df = pd.read_csv('/content/drive/My Drive/Tilburg University/DS&S/Thesis/Google Collab/UCI Breast Cancer Dataset/Data/data.csv')

df['diagnosis'].value_counts(normalize=True)

df['diagnosis'].value_counts()

df = df.iloc[:,:-1]

print(df.head)

#Split data
train, test =  train_test_split(df, train_size=0.85, test_size=0.15, random_state=42)

df = df.iloc[:,:-1]

train_id = train['id']
test_id = test['id']

train_data = train.iloc[:,1:]
test_data = test.iloc[:,1:]

#Scale data

# Training Data
train_x = train_data.iloc[:,1:]
train_x = MinMaxScaler().fit_transform(train_x)
print("Training Data :", train_x.shape)

# Testing Data
test_x = test_data.iloc[:,1:]
test_x = MinMaxScaler().fit_transform(test_x)
print("Testing Data :", test_x.shape)

#Remove labels

# Training Data
train_y = train_data.iloc[:,:1]
train_y[train_y=='M'] = 0
train_y[train_y=='B'] = 1
print("Training Data :", train_y.shape)

# Testing Data
test_y = test_data.iloc[:,:1]
test_y[test_y=='M'] = 0
test_y[test_y=='B'] = 1
print("Testing Data :", test_y.shape)

print(train_y)

train_y =train_y['diagnosis'].to_numpy()

train_y = train_y.astype(float)

"""# **3) Baseline Model**"""

test_y =test_y['diagnosis'].to_numpy() 
test_y = test_y.astype(float)

#Create Logistic Regression Model
logreg = LogisticRegression(max_iter= 3000)
logreg.fit(train_x,train_y)

#Get AUC score
logit_roc_auc = roc_auc_score(test_y, logreg.predict(test_x))
print(logit_roc_auc)

"""# **4) Vanilla Decision Tree**"""

#Create decision tree for specified depth of 5 and 10 
model = DecisionTreeClassifier(max_depth=10)
model.fit(train_x,train_y)
#max_depth=5,

res_pred = model.predict(test_x)

print(test_y)

print(res_pred)

#Get various scores
acc = accuracy_score(res_pred,test_y)
rec = recall_score(test_y, res_pred,average='macro')
prec = precision_score(test_y, res_pred,average='macro')
f1 = f1_score(test_y, res_pred,average='macro')
auc = roc_auc_score(test_y, res_pred,average='macro')
print('Accuracy:', acc)
print('Recall: ', rec)
print('Precision:', prec)
print('F1: ', f1)
print('AUC: ', auc)

"""# **5) Neural Network to extract logits**"""

#Prepare labels for Neural Network
y_train = np.array(keras.utils.to_categorical(train_y))
y_test = np.array(keras.utils.to_categorical(test_y))
print(y_test.shape)

#Metrics for Neural Network
def recall_m(y_true, y_pred):
    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))
    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))
    recall = true_positives / (possible_positives + K.epsilon())
    return recall

def precision_m(y_true, y_pred):
    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))
    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))
    precision = true_positives / (predicted_positives + K.epsilon())
    return precision

def f1_m(y_true, y_pred):
    precision = precision_m(y_true, y_pred)
    recall = recall_m(y_true, y_pred)
    return 2*((precision*recall)/(precision+recall+K.epsilon()))

def auc_m(y_true, y_pred):
     auc = tf.metrics.auc(y_true, y_pred)[1]
     K.get_session().run(tf.local_variables_initializer())
     return auc

#Built Neural Network
def build_model():
  inputs = layers.Input(shape=(30))
  x = layers.Dense(10,activation='relu',name='fc1')(inputs)
  
  x = layers.Dropout(rate=0.5, name='Dropout1')(x)

  x = layers.Dense(10,activation='relu',name='fc2')(x)

  x = layers.Dense(5,activation='relu',name='fc3')(x)

  x = layers.Dense(2,name='logits')(x)

  preds = layers.Activation('softmax',name='Softmax')(x)

  model = Model(inputs=inputs, outputs=preds)
  model.summary()
  return model
model = build_model()

#Set-up filepath and ModelCheckepoint with Earlystopping to save best performing moddel based on Validation AUC
filepath = "/content/drive/MyDrive/Tilburg University/DS&S/Thesis/Google Collab/UCI Breast Cancer Dataset/UCI Saved Models/UCI_MODELV6.hdf5"
model_checkpoint = ModelCheckpoint(filepath,  monitor='val_auc', save_best_only=True, mode='max')
es = EarlyStopping(monitor='val_auc', mode='max', verbose=0, patience=5)
model.compile(optimizer="adam", loss="categorical_crossentropy", metrics=['acc',f1_m,precision_m, recall_m,tf.keras.metrics.AUC(name='auc')])

#Set epochs and bach size, and train model 
num_epoch = 100
batch_size = 64
model1 = model.fit(x=train_x, y=y_train, epochs=num_epoch, batch_size=batch_size, validation_split=0.15,callbacks = [model_checkpoint,es])

#filepath = "/content/drive/My Drive/Tilburg University/DS&S/Thesis/Models/DownsampledV2.hdf5"
#Train performance
prediction_model = tf.keras.models.load_model(filepath, custom_objects={'f1_m':f1_m,'precision_m':precision_m, 'recall_m':recall_m, 'auc': tf.keras.metrics.AUC() }) 
loss, accuracy, f1_score, precision, recall, auc = prediction_model.evaluate(train_x,y_train, verbose=0, batch_size=64)

print('Train Accuracy:',accuracy)
print('Train Recall:',recall)
print('Train Precision:',precision)
print('Train F1:',f1_score)
print('Train AUC:',auc)
prediction_model.summary()

#Test performance
loss, accuracy, f1_score, precision, recall, auc = prediction_model.evaluate(test_x, y_test, verbose=0, batch_size=64)

print('Test Accuracy:',accuracy)
print('Test Recall:',recall)
print('Test Precision:',precision)
print('Test F1:',f1_score)
print('Test AUC:',auc)
prediction_model.summary()

#Best Performance
#best_filepath =  "/content/drive/MyDrive/Tilburg University/DS&S/Thesis/Google Collab/UCI Breast Cancer Dataset/UCI Saved Models/UCI_MODELV4.hdf5"
best_model = tf.keras.models.load_model(best_filepath, custom_objects={'f1_m':f1_m,'precision_m':precision_m, 'recall_m':recall_m, 'auc': tf.keras.metrics.AUC() }) 
loss, accuracy, f1_score, precision, recall, auc = best_model.evaluate(test_x,y_test, verbose=0, batch_size=64)

#print('Best Accuracy:',accuracy)
#print('Best Recall:',recall)
#print('Best Precision:',precision)
#print('Best F1:',f1_score)
print('Best AUC:',auc)
best_model.summary()

"""# **6) Extract Logits**"""

#Load the best model
#filepath =  "/content/drive/MyDrive/Tilburg University/DS&S/Thesis/Google Collab/UCI Breast Cancer Dataset/UCI Saved Models/UCI_MODELV4.hdf5"
model = tf.keras.models.load_model(best_filepath, custom_objects={'f1_m':f1_m,'precision_m':precision_m, 'recall_m':recall_m})

#Compile it again
model.compile(optimizer="adam", loss="categorical_crossentropy", metrics=['acc',f1_m,precision_m, recall_m,tf.keras.metrics.AUC()])
model.summary()

#Remove last softmax layer and predict again
model_sans_softmax = Model(inputs=model.input, outputs=model.get_layer("logits").output)
model_logits = model_sans_softmax.predict(train_x)

#Get the logits
soft_targets = model_logits

"""# **7) Get Student Decision Tree**

"""

#Set up Decision Tree for Knowledge Distillation at given depth 
model = DecisionTreeRegressor(max_depth=10)

#Train Decision Tree
model.fit(train_x,soft_targets)

#Get predictions
res_pred = model.predict(test_x)

#Covnvert continious predictions to categorical ones
pred_argmax = np.zeros_like(res_pred)
pred_argmax[np.arange(len(res_pred)), res_pred.argmax(1)] = 1

#Get scores of student decision tree
acc = accuracy_score(pred_argmax,y_test)
rec = recall_score(y_test, pred_argmax,average='macro')
prec = precision_score(y_test, pred_argmax,average='macro')
auc = roc_auc_score(y_test, pred_argmax,average='macro')
print('Accuracy:', acc)
print('Recall: ', rec)
print('Precision:', prec)
print('AUC: ', auc)